{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f872da38",
   "metadata": {},
   "source": [
    "### Hierarchical Probabilistic Neural Network Language Model, Morin & Y Bengio (2005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c197405c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Hierarchical Probabilistic Neural \n",
    "# Network Language Model, \n",
    "# Morin & Bengio (2005) \n",
    "# =========================\n",
    "\n",
    "# 1. Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# 2. Config\n",
    "n = 4        # context size = n-1 previous words + 1 target\n",
    "m = 10       # embedding dimension of each word [m x 1]\n",
    "h = 16       # hidden layer dimension [h x 1]\n",
    "d_node = 16  # dimension of each node in the tree [d_node x 1]\n",
    "\n",
    "epochs = 25\n",
    "lr = 0.01\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60c8e88",
   "metadata": {},
   "source": [
    "#### Toy dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d03db988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: ['a', 'ate', 'away', 'ball', 'barked', 'bird', 'book', 'boy', 'bright', 'cat', 'chased', 'dog', 'down', 'fast', 'fish', 'flew', 'food', 'girl', 'glows', 'high', 'jumped', 'letter', 'loudly', 'meowed', 'moon', 'mouse', 'played', 'quietly', 'read', 'sang', 'sat', 'shines', 'slept', 'softly', 'song', 'stars', 'sun', 'swam', 'sweetly', 'the', 'twinkle', 'wrote']\n",
      "Vocabulary Size: 42\n",
      "Vocabulary size: 42\n",
      "Number of training samples: 22\n",
      "Example context: [39, 9, 30] -> target: 12\n",
      "Example context words: ['the', 'cat', 'sat']\n",
      "Example target word: down\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 3. Toy Corpus (~20 sentences)\n",
    "# -----------------------------\n",
    "corpus = [\n",
    "    \"the cat sat down\",\n",
    "    \"the cat ate food\",\n",
    "    \"the dog sat down\",\n",
    "    \"the dog ate food\",\n",
    "    \"a cat chased a mouse\",\n",
    "    \"the dog chased the cat\",\n",
    "    \"a dog barked loudly\",\n",
    "    \"the cat meowed softly\",\n",
    "    \"the bird sang sweetly\",\n",
    "    \"a bird flew away\",\n",
    "    \"the fish swam fast\",\n",
    "    \"a fish jumped high\",\n",
    "    \"the boy played ball\",\n",
    "    \"the girl sang song\",\n",
    "    \"a boy read book\",\n",
    "    \"a girl wrote letter\",\n",
    "    \"the sun shines bright\",\n",
    "    \"the moon glows softly\",\n",
    "    \"the stars twinkle bright\",\n",
    "    \"a cat slept quietly\"\n",
    "]\n",
    "\n",
    "words = sorted(set(\" \".join(corpus).split()))\n",
    "\n",
    "print(\"Vocabulary:\", words)\n",
    "print(\"Vocabulary Size:\", len(words))\n",
    "\n",
    "# 4. Preprocessing\n",
    "tokens = set(\" \".join(corpus).split())\n",
    "word2idx = {word: i for i, word in enumerate(sorted(tokens))}\n",
    "idx2word = {i: word for word, i in word2idx.items()}\n",
    "V = len(word2idx)   # vocabulary size |V|\n",
    "\n",
    "# make context-target pairs for n-gram model\n",
    "def make_ngrams(corpus, n):\n",
    "    X, y = [], []\n",
    "    for sentence in corpus:\n",
    "        words = sentence.split()\n",
    "        for i in range(len(words) - n):\n",
    "            context = words[i:i+n]\n",
    "            target = words[i+n]\n",
    "            X.append([word2idx[w] for w in context])\n",
    "            y.append(word2idx[target])\n",
    "    return torch.tensor(X), torch.tensor(y)\n",
    "\n",
    "X, y = make_ngrams(corpus, n-1)\n",
    "\n",
    "\n",
    "print(\"Vocabulary size:\", V)\n",
    "print(\"Number of training samples:\", len(X))\n",
    "print('Example context:', X[0].tolist(), '-> target:', y[0].item())\n",
    "print('Example context words:', [idx2word[i] for i in X[0].tolist()])\n",
    "print('Example target word:', idx2word[y[0].item()])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd51b29",
   "metadata": {},
   "source": [
    "#### Model architecture and data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0f37161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Dataset/Dataloader\n",
    "class NGramDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "train_loader = DataLoader(NGramDataset(X, y), batch_size=4, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8e40a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_tree(tree, prefix=\"\", paths=None, depths=None, freqs=None):\n",
    "    \"\"\"\n",
    "    Analyze tree paths, depths and frequencies recursively\n",
    "    If freqs is None, uses weight=1 for each word\n",
    "    \"\"\"\n",
    "    # Initialize dictionaries\n",
    "    paths = {} if paths is None else paths\n",
    "    depths = {} if depths is None else depths\n",
    "    freqs = {} if freqs is None else freqs\n",
    "    \n",
    "    # If leaf node, record path, depth and frequency\n",
    "    if not tree.get('left') and not tree.get('right'):\n",
    "        word = tree['name']\n",
    "        freq = tree.get('freq', 1)  # Default frequency = 1 if not specified\n",
    "        paths[word] = prefix\n",
    "        depths[word] = len(prefix)\n",
    "        freqs[word] = freq\n",
    "        return paths, depths, freqs\n",
    "    \n",
    "    # Recurse on children\n",
    "    if tree.get('left'):\n",
    "        analyze_tree(tree['left'], prefix + \"0\", paths, depths, freqs)\n",
    "    if tree.get('right'):\n",
    "        analyze_tree(tree['right'], prefix + \"1\", paths, depths, freqs)\n",
    "    \n",
    "    return paths, depths, freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a41dc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_strict_balanced(words, d):\n",
    "    counter = [0]  # Mutable counter for naming internal nodes\n",
    "    \n",
    "    def build_recursive(words):\n",
    "        if not words:\n",
    "            return None\n",
    "        if len(words) == 1:\n",
    "            return {\"name\": words[0]}  # Leaf node - no parameters needed\n",
    "            \n",
    "        # Internal node with parameters\n",
    "        node_name = f\"n{counter[0]}\"\n",
    "        counter[0] += 1\n",
    "        \n",
    "        mid = len(words)//2\n",
    "        node = {\n",
    "            \"name\": node_name,\n",
    "            \"alpha\": torch.zeros(1),  # Bias parameter\n",
    "            \"N\": torch.randn(1, d),   # Node embedding [1 x d_node]\n",
    "            \"left\": build_recursive(words[:mid]),\n",
    "            \"right\": build_recursive(words[mid:])\n",
    "        }\n",
    "        return node\n",
    "    \n",
    "    return build_recursive(words)\n",
    "\n",
    "# Create balanced tree with parameters\n",
    "balanced_tree = build_strict_balanced(words, d_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6e44b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "# Hierarchical Softmax Model\n",
    "# =============================\n",
    "class HierarchicalSoftmaxLM(nn.Module):\n",
    "    def __init__(self, vocab_size, n, m, h, d_node, word2idx, paths, tree):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.n = n\n",
    "        self.m = m\n",
    "        self.h = h\n",
    "        self.d_node = d_node\n",
    "        self.word2idx = word2idx\n",
    "        self.paths = paths\n",
    "        self.tree = tree\n",
    "        \n",
    "        # word embeddings\n",
    "        self.embeddings = nn.Embedding(vocab_size, m)\n",
    "\n",
    "        # shared parameters\n",
    "        self.W = nn.Linear((n-1)*m, h, bias=False)   # context → hidden\n",
    "        self.U = nn.Linear(d_node, h, bias=False)    # node embedding → hidden\n",
    "        self.c = nn.Parameter(torch.zeros(h))        # hidden bias\n",
    "        self.beta = nn.Parameter(torch.randn(h))     # projection vector β\n",
    "\n",
    "        # Register tree parameters\n",
    "        def register_tree_params(node):\n",
    "            if node is None or not (\"left\" in node or \"right\" in node):\n",
    "                return\n",
    "            # Convert node parameters to nn.Parameters\n",
    "            node[\"alpha\"] = nn.Parameter(node[\"alpha\"])\n",
    "            node[\"N\"] = nn.Parameter(node[\"N\"])\n",
    "            # Register parameters with PyTorch\n",
    "            self.register_parameter(f\"alpha_{node['name']}\", node[\"alpha\"])\n",
    "            self.register_parameter(f\"N_{node['name']}\", node[\"N\"])\n",
    "            register_tree_params(node.get(\"left\"))\n",
    "            register_tree_params(node.get(\"right\"))\n",
    "        \n",
    "        register_tree_params(self.tree)\n",
    "\n",
    "        return\n",
    "    \n",
    "\n",
    "    def forward(self, context_idxs, target_idxs):\n",
    "        B = context_idxs.size(0)\n",
    "        \n",
    "        # Context representation x\n",
    "        ctx_emb = self.embeddings(context_idxs)   # [B, n-1, m]\n",
    "        x = ctx_emb.view(B, -1)                   # [B, (n-1)*m]\n",
    "        \n",
    "        losses = []\n",
    "        for i in range(B):\n",
    "            target_word = idx2word[target_idxs[i].item()]\n",
    "            path = self.paths[target_word]\n",
    "            \n",
    "            loss_i = 0.0\n",
    "            curr_node = self.tree\n",
    "            for bit in path:\n",
    "                # Use parameters directly from tree node\n",
    "                alpha = curr_node[\"alpha\"]\n",
    "                N = curr_node[\"N\"]\n",
    "                \n",
    "                # Compute hidden state\n",
    "                h_in = self.W(x[i].unsqueeze(0)) + self.U(N) + self.c\n",
    "                h_out = torch.tanh(h_in)\n",
    "                \n",
    "                # Compute probability\n",
    "                p = torch.sigmoid(alpha + (h_out @ self.beta))\n",
    "                \n",
    "                # Binary cross entropy\n",
    "                b_val = float(bit == \"1\")\n",
    "                loss_i += -(b_val * torch.log(p + 1e-9) + (1-b_val) * torch.log(1-p + 1e-9))\n",
    "                \n",
    "                # Move to next node\n",
    "                curr_node = curr_node[\"right\"] if bit == \"1\" else curr_node[\"left\"]\n",
    "            \n",
    "            losses.append(loss_i)\n",
    "        \n",
    "        return torch.mean(torch.stack(losses))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d3d471a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Architecture:\n",
      "==================\n",
      "Vocabulary size (V): 42\n",
      "Context size (n-1): 3\n",
      "Embedding dim (m): 10\n",
      "Hidden dim (h): 16\n",
      "\n",
      "Model Parameter Counts:\n",
      "----------------------------------------\n",
      "Word Embeddings       : 420\n",
      "Context Matrix W      : 480\n",
      "Node Matrix U         : 256\n",
      "Hidden Bias c         : 16\n",
      "Projection Vector β   : 16\n",
      "Tree Node Parameters  : 697\n",
      "----------------------------------------\n",
      "Total Parameters (manual) : 1,885\n",
      "Total Parameters (model)  : 1,885\n"
     ]
    }
   ],
   "source": [
    "# =============================\n",
    "# Model definition\n",
    "# =============================\n",
    "\n",
    "device = torch.device(\"cpu\")  # force CPU for small data\n",
    "paths, depths, freqs = analyze_tree(balanced_tree)\n",
    "model = HierarchicalSoftmaxLM(V, n, m, h, d_node, word2idx, paths, balanced_tree).to(device)\n",
    "\n",
    "def count_model_parameters(model):\n",
    "    \"\"\"\n",
    "    Count and display parameter sizes for each component of the model\n",
    "    \"\"\"\n",
    "    def count_tree_params(node):\n",
    "        \"\"\"Count parameters in tree nodes recursively\"\"\"\n",
    "        if node is None or not (\"left\" in node or \"right\" in node):\n",
    "            return 0\n",
    "        # Count parameters in current node (alpha: 1, N: d_node)\n",
    "        node_params = 1 + node[\"N\"].numel()\n",
    "        # Add parameters from children\n",
    "        return node_params + count_tree_params(node.get(\"left\")) + count_tree_params(node.get(\"right\"))\n",
    "\n",
    "    # Count embedding parameters\n",
    "    emb_params = model.embeddings.weight.numel()\n",
    "    \n",
    "    # Count shared parameters\n",
    "    w_params = model.W.weight.numel()\n",
    "    u_params = model.U.weight.numel()\n",
    "    c_params = model.c.numel()\n",
    "    beta_params = model.beta.numel()\n",
    "    \n",
    "    # Count tree parameters\n",
    "    tree_params = count_tree_params(model.tree)\n",
    "    \n",
    "    # Print parameter counts\n",
    "    print(\"\\nModel Parameter Counts:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"Word Embeddings       : {emb_params:,d}\")\n",
    "    print(f\"Context Matrix W      : {w_params:,d}\")\n",
    "    print(f\"Node Matrix U         : {u_params:,d}\")\n",
    "    print(f\"Hidden Bias c         : {c_params:,d}\")\n",
    "    print(f\"Projection Vector β   : {beta_params:,d}\")\n",
    "    print(f\"Tree Node Parameters  : {tree_params:,d}\")\n",
    "    print(\"-\" * 40)\n",
    "    total_params_manual = emb_params + w_params + u_params + c_params + beta_params + tree_params\n",
    "    total_params_model = sum(p.numel() for p in model.parameters())\n",
    "\n",
    "    print(f\"Total Parameters (manual) : {total_params_manual:,d}\")\n",
    "    print(f\"Total Parameters (model)  : {total_params_model:,d}\")\n",
    "\n",
    "\n",
    "print(\"\\nModel Architecture:\")\n",
    "print(\"==================\")\n",
    "print(f\"Vocabulary size (V): {V}\")\n",
    "print(f\"Context size (n-1): {n-1}\")\n",
    "print(f\"Embedding dim (m): {m}\")\n",
    "print(f\"Hidden dim (h): {h}\")\n",
    "\n",
    "# Use after model creation\n",
    "count_model_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0646b0f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/home/anaconda3/envs/graphrag/lib/python3.10/site-packages/torch/autograd/__init__.py:200: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 6.1066\n",
      "Epoch 2: Loss = 4.1432\n",
      "Epoch 3: Loss = 3.2558\n",
      "Epoch 4: Loss = 2.9867\n",
      "Epoch 5: Loss = 2.6553\n",
      "Epoch 6: Loss = 2.4782\n",
      "Epoch 7: Loss = 2.2868\n",
      "Epoch 8: Loss = 2.0288\n",
      "Epoch 9: Loss = 1.9642\n",
      "Epoch 10: Loss = 1.7443\n",
      "Epoch 11: Loss = 1.7364\n",
      "Epoch 12: Loss = 1.4934\n",
      "Epoch 13: Loss = 1.3397\n",
      "Epoch 14: Loss = 1.2283\n",
      "Epoch 15: Loss = 1.0936\n",
      "Epoch 16: Loss = 0.9654\n",
      "Epoch 17: Loss = 0.8611\n",
      "Epoch 18: Loss = 0.7635\n",
      "Epoch 19: Loss = 0.7046\n",
      "Epoch 20: Loss = 0.6377\n",
      "Epoch 21: Loss = 0.5705\n",
      "Epoch 22: Loss = 0.5188\n",
      "Epoch 23: Loss = 0.4596\n",
      "Epoch 24: Loss = 0.4100\n",
      "Epoch 25: Loss = 0.3693\n"
     ]
    }
   ],
   "source": [
    "# =============================\n",
    "# Training\n",
    "# =============================\n",
    "\n",
    "\n",
    "device = torch.device(\"cpu\")  # force CPU for small data\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for context, target in train_loader:\n",
    "        context, target = context.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = model(context, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}: Loss = {total_loss/len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bcdbf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ffd4da33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Context: ['the', 'cat', 'sat']\n",
      "  1. 'down' (0.7364)\n",
      "  2. 'bright' (0.0621)\n",
      "  3. 'cat' (0.0587)\n",
      "  4. 'fast' (0.0340)\n",
      "  5. 'food' (0.0197)\n",
      "\n",
      "Context: ['a', 'cat', 'chased']\n",
      "  1. 'a' (0.7514)\n",
      "  2. 'away' (0.0852)\n",
      "  3. 'loudly' (0.0278)\n",
      "  4. 'chased' (0.0213)\n",
      "  5. 'letter' (0.0212)\n",
      "\n",
      "Context: ['a', 'dog', 'barked']\n",
      "  1. 'loudly' (0.6891)\n",
      "  2. 'letter' (0.0563)\n",
      "  3. 'bright' (0.0481)\n",
      "  4. 'mouse' (0.0410)\n",
      "  5. 'played' (0.0406)\n",
      "\n",
      "Context: ['the', 'stars', 'glows']\n",
      "  1. 'down' (0.2803)\n",
      "  2. 'bright' (0.1672)\n",
      "  3. 'cat' (0.1397)\n",
      "  4. 'softly' (0.1202)\n",
      "  5. 'fast' (0.1178)\n"
     ]
    }
   ],
   "source": [
    "def predict_next(context_words, k=5):\n",
    "    \"\"\"\n",
    "    Predict next word probabilities using hierarchical softmax tree\n",
    "    Args:\n",
    "        context_words: List of context words\n",
    "        k: Number of top predictions to return\n",
    "    Returns:\n",
    "        List of (word, probability) tuples\n",
    "    \"\"\"\n",
    "    context_idxs = torch.tensor([[word2idx[w] for w in context_words]])\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Get context embedding\n",
    "        ctx_emb = model.embeddings(context_idxs)   # [1, n-1, m]\n",
    "        x = ctx_emb.view(1, -1)                    # [1, (n-1)*m]\n",
    "        \n",
    "        def get_node_prob(node, x):\n",
    "            \"\"\"Compute probability of taking right path at node\"\"\"\n",
    "            if not node or not (\"left\" in node or \"right\" in node):\n",
    "                return 1.0\n",
    "            \n",
    "            # Get node parameters\n",
    "            alpha = node[\"alpha\"]\n",
    "            N = node[\"N\"]\n",
    "            \n",
    "            # Compute hidden state\n",
    "            h_in = model.W(x) + model.U(N) + model.c\n",
    "            h_out = torch.tanh(h_in)\n",
    "            \n",
    "            # Return probability of going right\n",
    "            return torch.sigmoid(alpha + (h_out @ model.beta)).item()\n",
    "        \n",
    "        def get_word_prob(word, x):\n",
    "            \"\"\"Compute probability of word by multiplying path probabilities\"\"\"\n",
    "            path = model.paths[word]\n",
    "            prob = 1.0\n",
    "            curr_node = model.tree\n",
    "            \n",
    "            for bit in path:\n",
    "                p = get_node_prob(curr_node, x)\n",
    "                prob *= p if bit == \"1\" else (1-p)\n",
    "                curr_node = curr_node[\"right\"] if bit == \"1\" else curr_node[\"left\"]\n",
    "            \n",
    "            return prob\n",
    "        \n",
    "        # Compute probabilities for all words\n",
    "        word_probs = [(word, get_word_prob(word, x)) for word in words]\n",
    "        \n",
    "        # Sort by probability and get top k\n",
    "        word_probs.sort(key=lambda x: x[1], reverse=True)\n",
    "        predictions = word_probs[:k]\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# Test predictions\n",
    "test_contexts = [\n",
    "    [\"the\", \"cat\", \"sat\"],\n",
    "    [\"a\", \"cat\", \"chased\"],\n",
    "    [\"a\", \"dog\", \"barked\"],\n",
    "    [\"the\", \"stars\", \"glows\"]\n",
    "]\n",
    "\n",
    "for context in test_contexts:\n",
    "    predictions = predict_next(context)\n",
    "    print(f\"\\nContext: {context}\")\n",
    "    for i, (word, prob) in enumerate(predictions, 1):\n",
    "        print(f\"  {i}. '{word}' ({prob:.4f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
