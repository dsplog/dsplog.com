{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1036452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Skip-Gram with Negative Sampling\n",
    "# =========================\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "\n",
    "# 1. Hyperparameters\n",
    "embedding_dim = 10\n",
    "context_size = 2   # number of words on each side\n",
    "num_negatives = 5  # number of negative samples\n",
    "epochs = 25\n",
    "lr = 0.01\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "948c4690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 3. Toy Corpus (~20 sentences)\n",
    "# -----------------------------\n",
    "corpus = [\n",
    "    \"the cat sat down\",\n",
    "    \"the cat ate food\",\n",
    "    \"the dog sat down\",\n",
    "    \"the dog ate food\",\n",
    "    \"a cat chased a mouse\",\n",
    "    \"the dog chased the cat\",\n",
    "    \"a dog barked loudly\",\n",
    "    \"the cat meowed softly\",\n",
    "    \"the bird sang sweetly\",\n",
    "    \"a bird flew away\",\n",
    "    \"the fish swam fast\",\n",
    "    \"a fish jumped high\",\n",
    "    \"the boy played ball\",\n",
    "    \"the girl sang song\",\n",
    "    \"a boy read book\",\n",
    "    \"a girl wrote letter\",\n",
    "    \"the sun shines bright\",\n",
    "    \"the moon glows softly\",\n",
    "    \"the stars twinkle bright\",\n",
    "    \"a cat slept quietly\"\n",
    "]\n",
    "\n",
    "\n",
    "# 2. Vocabulary\n",
    "tokens = sorted(list(set(\" \".join(corpus).split())))\n",
    "word2idx = {w: i for i, w in enumerate(tokens)}\n",
    "idx2word = {i: w for w, i in word2idx.items()}\n",
    "V = len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52300133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word       |    Noise Probability\n",
      "-----------------------------------\n",
      "a          |             0.073365\n",
      "ate        |             0.025938\n",
      "away       |             0.015423\n",
      "ball       |             0.015423\n",
      "barked     |             0.015423\n",
      "bird       |             0.025938\n",
      "book       |             0.015423\n",
      "boy        |             0.025938\n",
      "bright     |             0.025938\n",
      "cat        |             0.059127\n",
      "chased     |             0.025938\n",
      "dog        |             0.043623\n",
      "down       |             0.025938\n",
      "fast       |             0.015423\n",
      "fish       |             0.025938\n",
      "flew       |             0.015423\n",
      "food       |             0.025938\n",
      "girl       |             0.025938\n",
      "glows      |             0.015423\n",
      "high       |             0.015423\n",
      "jumped     |             0.015423\n",
      "letter     |             0.015423\n",
      "loudly     |             0.015423\n",
      "meowed     |             0.015423\n",
      "moon       |             0.015423\n",
      "mouse      |             0.015423\n",
      "played     |             0.015423\n",
      "quietly    |             0.015423\n",
      "read       |             0.015423\n",
      "sang       |             0.025938\n",
      "sat        |             0.025938\n",
      "shines     |             0.015423\n",
      "slept      |             0.015423\n",
      "softly     |             0.025938\n",
      "song       |             0.015423\n",
      "stars      |             0.015423\n",
      "sun        |             0.015423\n",
      "swam       |             0.015423\n",
      "sweetly    |             0.015423\n",
      "the        |             0.111626\n",
      "twinkle    |             0.015423\n",
      "wrote      |             0.015423\n"
     ]
    }
   ],
   "source": [
    "# 3. Noise distribution for negative sampling\n",
    "import collections\n",
    "counts = collections.Counter(\" \".join(corpus).split())\n",
    "total = sum(counts.values())\n",
    "freqs = torch.tensor([counts[w]/total for w in tokens], dtype=torch.float)\n",
    "# Use unigram^3/4 for negative sampling (Mikolov et al.)\n",
    "noise_dist = freqs ** 0.75\n",
    "noise_dist = noise_dist / noise_dist.sum()\n",
    "\n",
    "# Print the noise distribution with words\n",
    "print(f\"{'Word':<10} | {'Noise Probability':>20}\")\n",
    "print(\"-\" * 35)\n",
    "for w, p in zip(tokens, noise_dist):\n",
    "    print(f\"{w:<10} | {p.item():>20.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c041eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Generate Skip-Gram pairs\n",
    "def generate_skipgram_pairs(corpus, context_size=2):\n",
    "    pairs = []\n",
    "    for sentence in corpus:\n",
    "        words = sentence.split()\n",
    "        for i, target in enumerate(words):\n",
    "            target_idx = word2idx[target]\n",
    "            # context window\n",
    "            for j in range(max(0, i - context_size), min(len(words), i + context_size + 1)):\n",
    "                if j != i:\n",
    "                    context_idx = word2idx[words[j]]\n",
    "                    pairs.append((target_idx, context_idx))\n",
    "    return pairs\n",
    "\n",
    "pairs = generate_skipgram_pairs(corpus, context_size)\n",
    "\n",
    "# 5. Dataset\n",
    "class SkipGramDataset(Dataset):\n",
    "    def __init__(self, pairs):\n",
    "        self.pairs = pairs\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.pairs[idx]\n",
    "\n",
    "dataset = SkipGramDataset(pairs)\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66d1bdc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Center words: ['twinkle', 'dog', 'the', 'chased']\n",
      "Context words: ['stars', 'sat', 'sang', 'dog']\n"
     ]
    }
   ],
   "source": [
    "# Example of iterating through the DataLoader and printing words\n",
    "for center, context in dataloader:\n",
    "    center_words = [idx2word[idx.item()] for idx in center]\n",
    "    context_words = [idx2word[idx.item()] for idx in context]\n",
    "    \n",
    "    print(\"Center words:\", center_words)\n",
    "    print(\"Context words:\", context_words)\n",
    "    break  # Display only the first batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c14349f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 6. Skip-Gram Model\n",
    "\n",
    "class SkipGramNS(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super().__init__()\n",
    "        self.in_embed = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.out_embed = nn.Embedding(vocab_size, embedding_dim)\n",
    "    \n",
    "    def forward(self, center, context, neg_samples):\n",
    "        # center: [B]\n",
    "        # context: [B]\n",
    "        # neg_samples: [B, K]\n",
    "        v_c = self.in_embed(center)           # [B, D]\n",
    "        u_o = self.out_embed(context)         # [B, D]\n",
    "        u_k = self.out_embed(neg_samples)     # [B, K, D]\n",
    "\n",
    "        # positive score\n",
    "        pos_score = torch.sum(v_c * u_o, dim=1)  # [B]\n",
    "        pos_loss = F.logsigmoid(pos_score)\n",
    "\n",
    "        # negative score\n",
    "        neg_score = torch.bmm(u_k, v_c.unsqueeze(2)).squeeze()  # [B, K]\n",
    "        neg_loss = F.logsigmoid(-neg_score).sum(1)             # [B]\n",
    "\n",
    "        return -(pos_loss + neg_loss).mean()  # mean over batch\n",
    "\n",
    "model = SkipGramNS(V, embedding_dim)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f137462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 435.8474\n",
      "Epoch 2/20, Loss: 368.7665\n",
      "Epoch 3/20, Loss: 314.8301\n",
      "Epoch 4/20, Loss: 280.7955\n",
      "Epoch 5/20, Loss: 251.7243\n",
      "Epoch 6/20, Loss: 243.0566\n",
      "Epoch 7/20, Loss: 200.1051\n",
      "Epoch 8/20, Loss: 195.5157\n",
      "Epoch 9/20, Loss: 169.0322\n",
      "Epoch 10/20, Loss: 169.3974\n",
      "Epoch 11/20, Loss: 157.2252\n",
      "Epoch 12/20, Loss: 153.0578\n",
      "Epoch 13/20, Loss: 147.8771\n",
      "Epoch 14/20, Loss: 137.3757\n",
      "Epoch 15/20, Loss: 132.1392\n",
      "Epoch 16/20, Loss: 127.3621\n",
      "Epoch 17/20, Loss: 127.7830\n",
      "Epoch 18/20, Loss: 118.1502\n",
      "Epoch 19/20, Loss: 120.0880\n",
      "Epoch 20/20, Loss: 119.2882\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 7. Training loop\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for center, context in dataloader:\n",
    "        # generate negative samples\n",
    "        neg_samples = torch.multinomial(noise_dist, len(center)*num_negatives, replacement=True)\n",
    "        neg_samples = neg_samples.view(len(center), num_negatives)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = model(center, context, neg_samples)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b399a69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top predicted context words for 'cat': ['swam', 'ate', 'away', 'bird', 'moon']\n",
      "Top predicted context words for 'boy': ['loudly', 'moon', 'played', 'book', 'down']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def predict_top_context(center_word, top_k=5):\n",
    "    model.eval()  # set to eval mode\n",
    "    with torch.no_grad():\n",
    "        # get index of the center word\n",
    "        center_idx = torch.tensor([word2idx[center_word]])\n",
    "        # get embedding of the center word\n",
    "        v_c = model.in_embed(center_idx)  # [1, D]\n",
    "\n",
    "        # compute scores with all output embeddings\n",
    "        u_all = model.out_embed.weight  # [V, D]\n",
    "        scores = torch.matmul(u_all, v_c.t()).squeeze()  # [V]\n",
    "\n",
    "        # top k context words\n",
    "        topk_scores, topk_idx = torch.topk(scores, top_k)\n",
    "        top_words = [idx2word[i.item()] for i in topk_idx]\n",
    "        return top_words\n",
    "\n",
    "# Example usage\n",
    "center = 'cat'\n",
    "top_context = predict_top_context(center, top_k=5)\n",
    "print(f\"Top predicted context words for '{center}': {top_context}\")\n",
    "\n",
    "\n",
    "center = 'boy'\n",
    "top_context = predict_top_context(center, top_k=5)\n",
    "print(f\"Top predicted context words for '{center}': {top_context}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62857f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 predicted context words for 'cat':\n",
      "Word         |      Score\n",
      "-------------------------\n",
      "swam         |    -0.4673\n",
      "ate          |    -0.8462\n",
      "away         |    -0.9408\n",
      "bird         |    -0.9638\n",
      "moon         |    -1.0851\n",
      "\n",
      "\n",
      "Top 5 predicted context words for 'fish':\n",
      "Word         |      Score\n",
      "-------------------------\n",
      "bright       |    -0.7526\n",
      "the          |    -0.7723\n",
      "fast         |    -0.9207\n",
      "jumped       |    -0.9452\n",
      "swam         |    -1.3696\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def predict_top_context(center_word, top_k=5):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # get index of the center word\n",
    "        center_idx = torch.tensor([word2idx[center_word]])\n",
    "        # get embedding of the center word\n",
    "        v_c = model.in_embed(center_idx)  # [1, D]\n",
    "\n",
    "        # compute scores with all output embeddings\n",
    "        u_all = model.out_embed.weight  # [V, D]\n",
    "        scores = torch.matmul(u_all, v_c.t()).squeeze()  # [V]\n",
    "\n",
    "        # top k context words (excluding the center word itself)\n",
    "        scores[word2idx[center_word]] = -float('inf')  # exclude self\n",
    "        topk_scores, topk_idx = torch.topk(scores, top_k)\n",
    "\n",
    "        # prepare output\n",
    "        top_words = [idx2word[i.item()] for i in topk_idx]\n",
    "        top_scores = [s.item() for s in topk_scores]\n",
    "\n",
    "        print(f\"\\nTop {top_k} predicted context words for '{center_word}':\")\n",
    "        print(f\"{'Word':<12} | {'Score':>10}\")\n",
    "        print(\"-\" * 25)\n",
    "        for w, s in zip(top_words, top_scores):\n",
    "            print(f\"{w:<12} | {s:>10.4f}\")\n",
    "        print()\n",
    "\n",
    "        return list(zip(top_words, top_scores))\n",
    "\n",
    "# Example usage\n",
    "center = 'cat'\n",
    "_ = predict_top_context(center, top_k=5)\n",
    "\n",
    "center = 'fish'\n",
    "_ = predict_top_context(center, top_k=5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphrag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
