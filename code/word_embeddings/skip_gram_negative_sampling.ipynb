{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f1036452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Skip-Gram with Negative Sampling\n",
    "# =========================\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "\n",
    "# 1. Hyperparameters\n",
    "embedding_dim = 10\n",
    "context_size = 2   # number of words on each side\n",
    "num_negatives = 5  # number of negative samples\n",
    "epochs = 25\n",
    "lr = 0.01\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "948c4690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 3. Toy Corpus (~20 sentences)\n",
    "# -----------------------------\n",
    "corpus = [\n",
    "    \"the cat sat down\",\n",
    "    \"the cat ate food\",\n",
    "    \"the dog sat down\",\n",
    "    \"the dog ate food\",\n",
    "    \"a cat chased a mouse\",\n",
    "    \"the dog chased the cat\",\n",
    "    \"a dog barked loudly\",\n",
    "    \"the cat meowed softly\",\n",
    "    \"the bird sang sweetly\",\n",
    "    \"a bird flew away\",\n",
    "    \"the fish swam fast\",\n",
    "    \"a fish jumped high\",\n",
    "    \"the boy played ball\",\n",
    "    \"the girl sang song\",\n",
    "    \"a boy read book\",\n",
    "    \"a girl wrote letter\",\n",
    "    \"the sun shines bright\",\n",
    "    \"the moon glows softly\",\n",
    "    \"the stars twinkle bright\",\n",
    "    \"a cat slept quietly\"\n",
    "]\n",
    "\n",
    "\n",
    "# 2. Vocabulary\n",
    "tokens = sorted(list(set(\" \".join(corpus).split())))\n",
    "word2idx = {w: i for i, w in enumerate(tokens)}\n",
    "idx2word = {i: w for w, i in word2idx.items()}\n",
    "V = len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "52300133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word       |    Noise Probability\n",
      "-----------------------------------\n",
      "a          |             0.073365\n",
      "ate        |             0.025938\n",
      "away       |             0.015423\n",
      "ball       |             0.015423\n",
      "barked     |             0.015423\n",
      "bird       |             0.025938\n",
      "book       |             0.015423\n",
      "boy        |             0.025938\n",
      "bright     |             0.025938\n",
      "cat        |             0.059127\n",
      "chased     |             0.025938\n",
      "dog        |             0.043623\n",
      "down       |             0.025938\n",
      "fast       |             0.015423\n",
      "fish       |             0.025938\n",
      "flew       |             0.015423\n",
      "food       |             0.025938\n",
      "girl       |             0.025938\n",
      "glows      |             0.015423\n",
      "high       |             0.015423\n",
      "jumped     |             0.015423\n",
      "letter     |             0.015423\n",
      "loudly     |             0.015423\n",
      "meowed     |             0.015423\n",
      "moon       |             0.015423\n",
      "mouse      |             0.015423\n",
      "played     |             0.015423\n",
      "quietly    |             0.015423\n",
      "read       |             0.015423\n",
      "sang       |             0.025938\n",
      "sat        |             0.025938\n",
      "shines     |             0.015423\n",
      "slept      |             0.015423\n",
      "softly     |             0.025938\n",
      "song       |             0.015423\n",
      "stars      |             0.015423\n",
      "sun        |             0.015423\n",
      "swam       |             0.015423\n",
      "sweetly    |             0.015423\n",
      "the        |             0.111626\n",
      "twinkle    |             0.015423\n",
      "wrote      |             0.015423\n"
     ]
    }
   ],
   "source": [
    "# 3. Noise distribution for negative sampling\n",
    "import collections\n",
    "counts = collections.Counter(\" \".join(corpus).split())\n",
    "total = sum(counts.values())\n",
    "freqs = torch.tensor([counts[w]/total for w in tokens], dtype=torch.float)\n",
    "# Use unigram^3/4 for negative sampling (Mikolov et al.)\n",
    "noise_dist = freqs ** 0.75\n",
    "noise_dist = noise_dist / noise_dist.sum()\n",
    "\n",
    "# Print the noise distribution with words\n",
    "print(f\"{'Word':<10} | {'Noise Probability':>20}\")\n",
    "print(\"-\" * 35)\n",
    "for w, p in zip(tokens, noise_dist):\n",
    "    print(f\"{w:<10} | {p.item():>20.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4c041eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Generate Skip-Gram pairs\n",
    "def generate_skipgram_pairs(corpus, context_size=2):\n",
    "    pairs = []\n",
    "    for sentence in corpus:\n",
    "        words = sentence.split()\n",
    "        for i, target in enumerate(words):\n",
    "            target_idx = word2idx[target]\n",
    "            # context window\n",
    "            for j in range(max(0, i - context_size), min(len(words), i + context_size + 1)):\n",
    "                if j != i:\n",
    "                    context_idx = word2idx[words[j]]\n",
    "                    pairs.append((target_idx, context_idx))\n",
    "    return pairs\n",
    "\n",
    "pairs = generate_skipgram_pairs(corpus, context_size)\n",
    "\n",
    "# 5. Dataset\n",
    "class SkipGramDataset(Dataset):\n",
    "    def __init__(self, pairs):\n",
    "        self.pairs = pairs\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.pairs[idx]\n",
    "\n",
    "dataset = SkipGramDataset(pairs)\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "66d1bdc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Center words: ['jumped', 'ate', 'fish', 'sang']\n",
      "Context words: ['fish', 'dog', 'swam', 'bird']\n"
     ]
    }
   ],
   "source": [
    "# Example of iterating through the DataLoader and printing words\n",
    "for center, context in dataloader:\n",
    "    center_words = [idx2word[idx.item()] for idx in center]\n",
    "    context_words = [idx2word[idx.item()] for idx in context]\n",
    "    \n",
    "    print(\"Center words:\", center_words)\n",
    "    print(\"Context words:\", context_words)\n",
    "    break  # Display only the first batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1c14349f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 6. Skip-Gram Model\n",
    "\n",
    "class SkipGramNS(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super().__init__()\n",
    "        self.in_embed = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.out_embed = nn.Embedding(vocab_size, embedding_dim)\n",
    "    \n",
    "    def forward(self, center, context, neg_samples):\n",
    "        # center: [B]\n",
    "        # context: [B]\n",
    "        # neg_samples: [B, K]\n",
    "        v_c = self.in_embed(center)           # [B, D]\n",
    "        u_o = self.out_embed(context)         # [B, D]\n",
    "        u_k = self.out_embed(neg_samples)     # [B, K, D]\n",
    "\n",
    "        # positive score\n",
    "        pos_score = torch.sum(v_c * u_o, dim=1)  # [B]\n",
    "        pos_loss = F.logsigmoid(pos_score)\n",
    "\n",
    "        # negative score\n",
    "        neg_score = torch.bmm(u_k, v_c.unsqueeze(2)).squeeze()  # [B, K]\n",
    "        neg_loss = F.logsigmoid(-neg_score).sum(1)             # [B]\n",
    "\n",
    "        return -(pos_loss + neg_loss).mean()  # mean over batch\n",
    "\n",
    "model = SkipGramNS(V, embedding_dim)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4f137462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25, Loss: 375.2714\n",
      "Epoch 2/25, Loss: 312.9282\n",
      "Epoch 3/25, Loss: 287.3515\n",
      "Epoch 4/25, Loss: 243.2211\n",
      "Epoch 5/25, Loss: 212.7308\n",
      "Epoch 6/25, Loss: 195.3160\n",
      "Epoch 7/25, Loss: 179.5930\n",
      "Epoch 8/25, Loss: 168.7045\n",
      "Epoch 9/25, Loss: 160.8458\n",
      "Epoch 10/25, Loss: 144.2616\n",
      "Epoch 11/25, Loss: 134.3770\n",
      "Epoch 12/25, Loss: 131.6906\n",
      "Epoch 13/25, Loss: 130.2371\n",
      "Epoch 14/25, Loss: 123.8140\n",
      "Epoch 15/25, Loss: 119.5503\n",
      "Epoch 16/25, Loss: 115.5972\n",
      "Epoch 17/25, Loss: 115.2400\n",
      "Epoch 18/25, Loss: 111.4093\n",
      "Epoch 19/25, Loss: 107.9728\n",
      "Epoch 20/25, Loss: 108.9566\n",
      "Epoch 21/25, Loss: 107.6192\n",
      "Epoch 22/25, Loss: 102.8265\n",
      "Epoch 23/25, Loss: 102.7075\n",
      "Epoch 24/25, Loss: 102.8956\n",
      "Epoch 25/25, Loss: 99.3217\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 7. Training loop\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for center, context in dataloader:\n",
    "        # generate negative samples\n",
    "        neg_samples = torch.multinomial(noise_dist, len(center)*num_negatives, replacement=True)\n",
    "        neg_samples = neg_samples.view(len(center), num_negatives)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = model(center, context, neg_samples)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f9336e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 cosine-similar context words for 'chased':\n",
      "Word         | Cosine Sim\n",
      "----------------------------\n",
      "cat          |     0.0313\n",
      "dog          |    -0.0638\n",
      "mouse        |    -0.0764\n",
      "flew         |    -0.0917\n",
      "sun          |    -0.1016\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def predict_top_context(center_word, top_k=5):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # get index of the center word\n",
    "        center_idx = torch.tensor([word2idx[center_word]])\n",
    "        # get embedding of the center word\n",
    "        v_c = model.in_embed(center_idx)  # [1, D]\n",
    "        v_c_norm = v_c / v_c.norm(dim=1, keepdim=True)\n",
    "\n",
    "        # get all output embeddings and normalize\n",
    "        u_all = model.out_embed.weight  # [V, D]\n",
    "        u_all_norm = u_all / u_all.norm(dim=1, keepdim=True)\n",
    "\n",
    "        # cosine similarity\n",
    "        scores = torch.matmul(u_all_norm, v_c_norm.t()).squeeze()  # [V]\n",
    "\n",
    "        # exclude center word itself\n",
    "        scores[word2idx[center_word]] = -float('inf')\n",
    "        topk_scores, topk_idx = torch.topk(scores, top_k)\n",
    "\n",
    "        top_words = [idx2word[i.item()] for i in topk_idx]\n",
    "        top_scores = [s.item() for s in topk_scores]\n",
    "\n",
    "        print(f\"\\nTop {top_k} cosine-similar context words for '{center_word}':\")\n",
    "        print(f\"{'Word':<12} | {'Cosine Sim':>10}\")\n",
    "        print(\"-\" * 28)\n",
    "        for w, s in zip(top_words, top_scores):\n",
    "            print(f\"{w:<12} | {s:>10.4f}\")\n",
    "        print()\n",
    "\n",
    "        return list(zip(top_words, top_scores))\n",
    "\n",
    "# Example usage\n",
    "center = 'chased'\n",
    "_ = predict_top_context(center, top_k=5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphrag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
